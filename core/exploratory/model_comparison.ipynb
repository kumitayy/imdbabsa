{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries loaded | PyTorch: 2.6.0+cu118 | CUDA: True | Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import all necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.calibration import calibration_curve\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, BertTokenizer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Setup\n",
    "warnings.filterwarnings('ignore')\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"âœ… Libraries loaded | PyTorch: {torch.__version__} | CUDA: {torch.cuda.is_available()} | Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LCF-ATEPC model defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import LCF-ATEPC model from local file\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "class LCF_ATEPC(nn.Module):\n",
    "    \"\"\"\n",
    "    Local copy of LCF-ATEPC model for loading\n",
    "    \"\"\"\n",
    "    def __init__(self, pretrained_model_name='bert-base-uncased',\n",
    "                 hidden_size=768, num_aspect_labels=2, num_sentiment_labels=2,\n",
    "                 context_window=3, dropout_rate=0.15):\n",
    "        super(LCF_ATEPC, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(pretrained_model_name)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.context_window = context_window\n",
    "        \n",
    "        # Dropout and normalization\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.ate_layer_norm = nn.LayerNorm(hidden_size)\n",
    "        self.apc_layer_norm = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "        # Self-attention for aspects\n",
    "        self.aspect_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=dropout_rate,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Fusion layer\n",
    "        self.fusion_fc = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.fusion_act = nn.GELU()\n",
    "        \n",
    "        # Classifiers\n",
    "        self.aspect_classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(hidden_size // 2),\n",
    "            nn.Linear(hidden_size // 2, num_aspect_labels)\n",
    "        )\n",
    "        \n",
    "        self.sentiment_classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(hidden_size // 2),\n",
    "            nn.Linear(hidden_size // 2, num_sentiment_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None, aspect_positions=None):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids,\n",
    "                            output_hidden_states=True)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        \n",
    "        # For inference we only need sentiment prediction\n",
    "        apc_logits = None\n",
    "        if aspect_positions is not None:\n",
    "            batch_size, seq_len, hid = sequence_output.size()\n",
    "            apc_feats = []\n",
    "\n",
    "            actual_batch_size = min(batch_size, len(aspect_positions))\n",
    "            \n",
    "            for b in range(actual_batch_size):\n",
    "                try:\n",
    "                    spans = aspect_positions[b]\n",
    "                    \n",
    "                    if not spans:\n",
    "                        apc_feats.append(sequence_output[b, 0])\n",
    "                        continue\n",
    "                        \n",
    "                    # Normalize span format\n",
    "                    if not isinstance(spans, list) and not isinstance(spans, tuple):\n",
    "                        spans = [spans]\n",
    "                    elif len(spans) == 2 and all(isinstance(x, (int, float)) for x in spans):\n",
    "                        spans = [spans]\n",
    "                    \n",
    "                    batch_span_feats = []\n",
    "                    for span in spans:\n",
    "                        if isinstance(span, (list, tuple)) and len(span) == 2:\n",
    "                            s, e = span\n",
    "                            s = max(0, min(int(s), seq_len - 1))\n",
    "                            e = max(s, min(int(e), seq_len - 1))\n",
    "                            \n",
    "                            # Local context around aspect\n",
    "                            left = max(0, s - self.context_window)\n",
    "                            right = min(seq_len, e + 1 + self.context_window)\n",
    "                            \n",
    "                            # Aspect representation\n",
    "                            aspect_repr = sequence_output[b, s:e, :]\n",
    "                            if aspect_repr.size(0) == 0:\n",
    "                                aspect_repr = sequence_output[b, 0].unsqueeze(0)\n",
    "                            else:\n",
    "                                aspect_repr = aspect_repr.mean(dim=0, keepdim=True)\n",
    "                                \n",
    "                            # Context representation\n",
    "                            context_repr = sequence_output[b, left:right, :]\n",
    "                            \n",
    "                            # Self-attention to improve aspect-context relationship\n",
    "                            if context_repr.size(0) > 1:\n",
    "                                context_mask = torch.ones(context_repr.size(0), device=context_repr.device)\n",
    "                                context_attn_output, _ = self.aspect_attention(\n",
    "                                    context_repr.unsqueeze(0),\n",
    "                                    context_repr.unsqueeze(0),\n",
    "                                    context_repr.unsqueeze(0),\n",
    "                                    key_padding_mask=(1 - context_mask.unsqueeze(0)).bool()\n",
    "                                )\n",
    "                                context_repr = context_attn_output.squeeze(0)\n",
    "                                context_repr = context_repr.mean(dim=0, keepdim=True)\n",
    "                            else:\n",
    "                                context_repr = context_repr.mean(dim=0, keepdim=True)\n",
    "                            \n",
    "                            # Combine aspect and context\n",
    "                            combined = torch.cat([aspect_repr, context_repr], dim=1)\n",
    "                            fused = self.fusion_fc(combined.view(-1))\n",
    "                            fused = self.fusion_act(fused)\n",
    "                            \n",
    "                            batch_span_feats.append(fused)\n",
    "                    \n",
    "                    if not batch_span_feats:\n",
    "                        apc_feats.append(sequence_output[b, 0])\n",
    "                    else:\n",
    "                        span_tensor = torch.stack(batch_span_feats)\n",
    "                        apc_feats.append(span_tensor.mean(dim=0))\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    apc_feats.append(sequence_output[b, 0])\n",
    "            \n",
    "            # Handle case when batch is smaller than expected\n",
    "            if actual_batch_size < batch_size:\n",
    "                for b in range(actual_batch_size, batch_size):\n",
    "                    apc_feats.append(sequence_output[b, 0])\n",
    "            \n",
    "            # Stack all features and normalize\n",
    "            apc_tensor = torch.stack(apc_feats, dim=0)\n",
    "            apc_tensor = self.apc_layer_norm(apc_tensor)\n",
    "            \n",
    "            # Sentiment classifier\n",
    "            apc_logits = self.sentiment_classifier(apc_tensor)\n",
    "\n",
    "        return apc_logits\n",
    "\n",
    "print(\"âœ… LCF-ATEPC model defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Model loader created!\n"
     ]
    }
   ],
   "source": [
    "# Define class for loading all models\n",
    "class ModelLoader:\n",
    "    \"\"\"\n",
    "    Loader for 3 models from models/ folder\n",
    "    \"\"\"\n",
    "    def __init__(self, models_dir='../models'):\n",
    "        self.models_dir = models_dir\n",
    "        self.models = {}\n",
    "        self.tokenizers = {}\n",
    "        self.device = device\n",
    "        \n",
    "    def load_lcf_atepc(self):\n",
    "        \"\"\"Load LCF-ATEPC model\"\"\"\n",
    "        print(\"ðŸ”„ Loading LCF-ATEPC model...\")\n",
    "        model_path = os.path.join(self.models_dir, 'lcf_atepc')\n",
    "        \n",
    "        # Load configuration\n",
    "        with open(os.path.join(model_path, \"inference_config.json\"), \"r\") as f:\n",
    "            config = json.load(f)\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer_path = os.path.join(model_path, \"tokenizer\")\n",
    "        tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
    "        \n",
    "        # Create model\n",
    "        model = LCF_ATEPC(\n",
    "            pretrained_model_name=config[\"pretrained_model_name\"],\n",
    "            num_aspect_labels=config[\"num_aspect_labels\"],\n",
    "            num_sentiment_labels=config[\"num_sentiment_labels\"],\n",
    "            context_window=config[\"context_window\"]\n",
    "        )\n",
    "        \n",
    "        # Load weights\n",
    "        model_weights_path = os.path.join(model_path, \"model.pt\")\n",
    "        model.load_state_dict(torch.load(model_weights_path, map_location=self.device))\n",
    "        model.to(self.device)\n",
    "        model.eval()\n",
    "        \n",
    "        self.models['lcf_atepc'] = model\n",
    "        self.tokenizers['lcf_atepc'] = tokenizer\n",
    "        print(\"âœ… LCF-ATEPC loaded successfully!\")\n",
    "        \n",
    "    def load_roberta_model(self, model_name):\n",
    "        \"\"\"Load RoBERTa model with flexible path detection\"\"\"\n",
    "        print(f\"ðŸ”„ Loading {model_name} model...\")\n",
    "        base_model_path = os.path.join(self.models_dir, model_name)\n",
    "        \n",
    "        # Handle special case for roberta_absa_final\n",
    "        if model_name == 'roberta_absa_final':\n",
    "            # Try calibrated directory first\n",
    "            calibrated_path = os.path.join(base_model_path, 'calibrated')\n",
    "            if os.path.exists(calibrated_path) and os.path.exists(os.path.join(calibrated_path, 'tokenizer.json')):\n",
    "                model_path = calibrated_path\n",
    "                print(f\"   ðŸ“ Using calibrated model from: {calibrated_path}\")\n",
    "            else:\n",
    "                # Fallback to checkpoint directories\n",
    "                checkpoint_dirs = [d for d in os.listdir(base_model_path) if d.startswith('checkpoint-')]\n",
    "                if checkpoint_dirs:\n",
    "                    # Use the highest numbered checkpoint\n",
    "                    latest_checkpoint = max(checkpoint_dirs, key=lambda x: int(x.split('-')[1]))\n",
    "                    model_path = os.path.join(base_model_path, latest_checkpoint)\n",
    "                    print(f\"   ðŸ“ Using checkpoint: {latest_checkpoint}\")\n",
    "                else:\n",
    "                    raise ValueError(f\"No valid model path found for {model_name}\")\n",
    "        else:\n",
    "            model_path = base_model_path\n",
    "        \n",
    "        # Load tokenizer and model\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
    "        \n",
    "        # For calibrated model, we need to handle the custom model file\n",
    "        if model_name == 'roberta_absa_final' and 'calibrated' in model_path:\n",
    "            # Load config first\n",
    "            config_path = os.path.join(model_path, 'config.json')\n",
    "            if not os.path.exists(config_path):\n",
    "                # Use a default config from another roberta model\n",
    "                config_path = os.path.join(self.models_dir, 'roberta_absa', 'config.json')\n",
    "            \n",
    "            from transformers import RobertaConfig\n",
    "            config = RobertaConfig.from_pretrained(config_path)\n",
    "            model = RobertaForSequenceClassification(config)\n",
    "            \n",
    "            # Load the calibrated weights\n",
    "            calibrated_model_path = os.path.join(model_path, 'calibrated_model.pt')\n",
    "            if os.path.exists(calibrated_model_path):\n",
    "                checkpoint = torch.load(calibrated_model_path, map_location=self.device)\n",
    "                \n",
    "                # Handle different checkpoint formats\n",
    "                if isinstance(checkpoint, dict):\n",
    "                    if 'model_state_dict' in checkpoint:\n",
    "                        state_dict = checkpoint['model_state_dict']\n",
    "                        print(f\"   ðŸ“¦ Extracting model weights from 'model_state_dict' key\")\n",
    "                    elif 'state_dict' in checkpoint:\n",
    "                        state_dict = checkpoint['state_dict']\n",
    "                        print(f\"   ðŸ“¦ Extracting model weights from 'state_dict' key\")\n",
    "                    else:\n",
    "                        # Assume the checkpoint itself is the state dict\n",
    "                        state_dict = checkpoint\n",
    "                        print(f\"   ðŸ“¦ Using checkpoint directly as state_dict\")\n",
    "                else:\n",
    "                    state_dict = checkpoint\n",
    "                \n",
    "                # Remove \"model.\" prefix from keys if present (for custom ABSA models)\n",
    "                cleaned_state_dict = {}\n",
    "                prefix_removed = False\n",
    "                for key, value in state_dict.items():\n",
    "                    if key.startswith('model.') and not key.startswith('model_'):\n",
    "                        # Remove \"model.\" prefix\n",
    "                        new_key = key[6:]  # Remove \"model.\" (6 characters)\n",
    "                        # Skip non-standard ABSA layers that don't exist in RobertaForSequenceClassification\n",
    "                        if not any(layer in new_key for layer in ['aspect_attention', 'aspect_marker_detector']):\n",
    "                            cleaned_state_dict[new_key] = value\n",
    "                            prefix_removed = True\n",
    "                    elif key == 'temperature':\n",
    "                        # Skip temperature parameter (used for calibration)\n",
    "                        continue\n",
    "                    else:\n",
    "                        cleaned_state_dict[key] = value\n",
    "                \n",
    "                if prefix_removed:\n",
    "                    print(f\"   ðŸ”§ Removed 'model.' prefix from parameter names\")\n",
    "                    print(f\"   ðŸŽ¯ Filtered out {len(state_dict) - len(cleaned_state_dict)} incompatible parameters\")\n",
    "                    state_dict = cleaned_state_dict\n",
    "                \n",
    "                model.load_state_dict(state_dict, strict=False)\n",
    "                print(f\"   âœ… Loaded calibrated weights from: calibrated_model.pt\")\n",
    "            else:\n",
    "                raise ValueError(f\"Calibrated model file not found: {calibrated_model_path}\")\n",
    "        else:\n",
    "            model = RobertaForSequenceClassification.from_pretrained(model_path)\n",
    "        \n",
    "        model.to(self.device)\n",
    "        model.eval()\n",
    "        \n",
    "        self.models[model_name] = model\n",
    "        self.tokenizers[model_name] = tokenizer\n",
    "        print(f\"âœ… {model_name} loaded successfully!\")\n",
    "        \n",
    "    def load_all_models(self):\n",
    "        \"\"\"Load all models\"\"\"\n",
    "        print(\"ðŸš€ Starting to load all models...\")\n",
    "        \n",
    "        # Load LCF-ATEPC\n",
    "        self.load_lcf_atepc()\n",
    "        \n",
    "        # Load all RoBERTa models\n",
    "        roberta_models = ['roberta_absa', 'roberta_absa_pseudo', 'roberta_absa_final']\n",
    "        for model_name in roberta_models:\n",
    "            try:\n",
    "                self.load_roberta_model(model_name)\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Failed to load {model_name}: {e}\")\n",
    "                print(f\"   Skipping {model_name} and continuing with other models...\")\n",
    "        \n",
    "        print(\"ðŸŽ‰ Model loading completed!\")\n",
    "        print(f\"ðŸ“Š Successfully loaded models: {len(self.models)}\")\n",
    "        if len(self.models) < 4:\n",
    "            print(f\"âš ï¸  Some models failed to load. Available models: {list(self.models.keys())}\")\n",
    "        \n",
    "    def get_model_info(self):\n",
    "        \"\"\"Get information about loaded models\"\"\"\n",
    "        info = {}\n",
    "        for name, model in self.models.items():\n",
    "            info[name] = {\n",
    "                'parameters': sum(p.numel() for p in model.parameters()),\n",
    "                'trainable_parameters': sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
    "                'architecture': type(model).__name__\n",
    "            }\n",
    "        return info\n",
    "\n",
    "# Create model loader\n",
    "loader = ModelLoader()\n",
    "print(\"ðŸ”§ Model loader created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Testing individual model loading...\n",
      "ðŸ”„ Loading LCF-ATEPC model...\n",
      "âœ… LCF-ATEPC loaded successfully!\n",
      "âœ… LCF-ATEPC test passed\n",
      "\n",
      "ðŸ§ª Testing roberta_absa...\n",
      "ðŸ”„ Loading roberta_absa model...\n",
      "âœ… roberta_absa loaded successfully!\n",
      "âœ… roberta_absa test passed\n",
      "\n",
      "ðŸ§ª Testing roberta_absa_pseudo...\n",
      "ðŸ”„ Loading roberta_absa_pseudo model...\n",
      "âœ… roberta_absa_pseudo loaded successfully!\n",
      "âœ… roberta_absa_pseudo test passed\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ðŸ“ˆ Information about loaded models:\n",
      "================================================================================\n",
      "\n",
      "ðŸŽ¯ LCF_ATEPC:\n",
      "   - Architecture: LCF_ATEPC\n",
      "   - Total parameters: 113,621,764\n",
      "   - Trainable parameters: 113,621,764\n",
      "   - Model size: 433.4 MB\n",
      "\n",
      "ðŸŽ¯ ROBERTA_ABSA:\n",
      "   - Architecture: RobertaForSequenceClassification\n",
      "   - Total parameters: 124,647,170\n",
      "   - Trainable parameters: 124,647,170\n",
      "   - Model size: 475.5 MB\n",
      "\n",
      "ðŸŽ¯ ROBERTA_ABSA_PSEUDO:\n",
      "   - Architecture: RobertaForSequenceClassification\n",
      "   - Total parameters: 124,647,170\n",
      "   - Trainable parameters: 124,647,170\n",
      "   - Model size: 475.5 MB\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test loading each model individually first\n",
    "print(\"ðŸ” Testing individual model loading...\")\n",
    "\n",
    "# Test LCF-ATEPC\n",
    "try:\n",
    "    loader.load_lcf_atepc()\n",
    "    print(\"âœ… LCF-ATEPC test passed\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ LCF-ATEPC test failed: {e}\")\n",
    "\n",
    "# Test each RoBERTa model individually\n",
    "roberta_models = ['roberta_absa', 'roberta_absa_pseudo']\n",
    "for model_name in roberta_models:\n",
    "    try:\n",
    "        print(f\"\\nðŸ§ª Testing {model_name}...\")\n",
    "        loader.load_roberta_model(model_name)\n",
    "        print(f\"âœ… {model_name} test passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {model_name} test failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Display model information\n",
    "print(\"\\nðŸ“ˆ Information about loaded models:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "model_info = loader.get_model_info()\n",
    "if model_info:\n",
    "    for name, info in model_info.items():\n",
    "        print(f\"\\nðŸŽ¯ {name.upper()}:\")\n",
    "        print(f\"   - Architecture: {info['architecture']}\")\n",
    "        print(f\"   - Total parameters: {info['parameters']:,}\")\n",
    "        print(f\"   - Trainable parameters: {info['trainable_parameters']:,}\")\n",
    "        print(f\"   - Model size: {info['parameters'] * 4 / (1024**2):.1f} MB\")\n",
    "else:\n",
    "    print(\"âŒ No models were loaded successfully!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Created 30 test examples\n",
      "ðŸ“Š Categories: {'Contradictory': 15, 'Consistent': 10, 'Subtle': 5}\n"
     ]
    }
   ],
   "source": [
    "# Create 30 test examples for comprehensive evaluation\n",
    "test_examples = [\n",
    "    # Contradictory sentiments (15 examples)\n",
    "    {\"text\": \"This movie has stunning visual effects, but the plot is absolutely boring.\", \"aspect\": \"visual effects\", \"expected_sentiment\": \"positive\", \"category\": \"Contradictory\"},\n",
    "    {\"text\": \"The acting was terrible, but the cinematography is excellent.\", \"aspect\": \"acting\", \"expected_sentiment\": \"negative\", \"category\": \"Contradictory\"},\n",
    "    {\"text\": \"I didn't like the movie overall, but the soundtrack is magnificent.\", \"aspect\": \"soundtrack\", \"expected_sentiment\": \"positive\", \"category\": \"Contradictory\"},\n",
    "    {\"text\": \"Great movie with excellent acting, but the dialogue is poorly written.\", \"aspect\": \"dialogue\", \"expected_sentiment\": \"negative\", \"category\": \"Contradictory\"},\n",
    "    {\"text\": \"Weak plot, but the special effects are mind-blowing.\", \"aspect\": \"special effects\", \"expected_sentiment\": \"positive\", \"category\": \"Contradictory\"},\n",
    "    {\"text\": \"Bad movie overall, but the lead actor gave an outstanding performance.\", \"aspect\": \"lead actor\", \"expected_sentiment\": \"positive\", \"category\": \"Contradictory\"},\n",
    "    {\"text\": \"Excellent film with great direction, but the music is annoying.\", \"aspect\": \"music\", \"expected_sentiment\": \"negative\", \"category\": \"Contradictory\"},\n",
    "    {\"text\": \"Poor storyline, but the costume design is absolutely brilliant.\", \"aspect\": \"costume design\", \"expected_sentiment\": \"positive\", \"category\": \"Contradictory\"},\n",
    "    {\"text\": \"Amazing movie with superb acting, but the editing is choppy.\", \"aspect\": \"editing\", \"expected_sentiment\": \"negative\", \"category\": \"Contradictory\"},\n",
    "    {\"text\": \"Disappointing film overall, but the production design is stunning.\", \"aspect\": \"production design\", \"expected_sentiment\": \"positive\", \"category\": \"Contradictory\"},\n",
    "    {\"text\": \"Great movie but the supporting cast was disappointing.\", \"aspect\": \"supporting cast\", \"expected_sentiment\": \"negative\", \"category\": \"Contradictory\"},\n",
    "    {\"text\": \"Boring film with excellent sound design.\", \"aspect\": \"sound design\", \"expected_sentiment\": \"positive\", \"category\": \"Contradictory\"},\n",
    "    {\"text\": \"Fantastic movie but the script has major flaws.\", \"aspect\": \"script\", \"expected_sentiment\": \"negative\", \"category\": \"Contradictory\"},\n",
    "    {\"text\": \"Poor film overall but the directing is masterful.\", \"aspect\": \"directing\", \"expected_sentiment\": \"positive\", \"category\": \"Contradictory\"},\n",
    "    {\"text\": \"Excellent movie with terrible camera work.\", \"aspect\": \"camera work\", \"expected_sentiment\": \"negative\", \"category\": \"Contradictory\"},\n",
    "    \n",
    "    # Consistent sentiments (10 examples)\n",
    "    {\"text\": \"Amazing movie! The actors perform brilliantly.\", \"aspect\": \"actors\", \"expected_sentiment\": \"positive\", \"category\": \"Consistent\"},\n",
    "    {\"text\": \"Terrible movie with bad script and poor acting.\", \"aspect\": \"script\", \"expected_sentiment\": \"negative\", \"category\": \"Consistent\"},\n",
    "    {\"text\": \"Magnificent film with stunning special effects.\", \"aspect\": \"special effects\", \"expected_sentiment\": \"positive\", \"category\": \"Consistent\"},\n",
    "    {\"text\": \"Awful movie with horrible cinematography.\", \"aspect\": \"cinematography\", \"expected_sentiment\": \"negative\", \"category\": \"Consistent\"},\n",
    "    {\"text\": \"Outstanding film with excellent direction.\", \"aspect\": \"direction\", \"expected_sentiment\": \"positive\", \"category\": \"Consistent\"},\n",
    "    {\"text\": \"Poor movie with weak dialogue.\", \"aspect\": \"dialogue\", \"expected_sentiment\": \"negative\", \"category\": \"Consistent\"},\n",
    "    {\"text\": \"Brilliant film with amazing soundtrack.\", \"aspect\": \"soundtrack\", \"expected_sentiment\": \"positive\", \"category\": \"Consistent\"},\n",
    "    {\"text\": \"Disappointing movie with terrible editing.\", \"aspect\": \"editing\", \"expected_sentiment\": \"negative\", \"category\": \"Consistent\"},\n",
    "    {\"text\": \"Fantastic movie with superb acting.\", \"aspect\": \"acting\", \"expected_sentiment\": \"positive\", \"category\": \"Consistent\"},\n",
    "    {\"text\": \"Bad film with poor visual effects.\", \"aspect\": \"visual effects\", \"expected_sentiment\": \"negative\", \"category\": \"Consistent\"},\n",
    "    \n",
    "    # Subtle sentiments (5 examples)\n",
    "    {\"text\": \"The movie is not bad, the music is quite pleasant.\", \"aspect\": \"music\", \"expected_sentiment\": \"positive\", \"category\": \"Subtle\"},\n",
    "    {\"text\": \"The director tried but it didn't work out well.\", \"aspect\": \"director\", \"expected_sentiment\": \"negative\", \"category\": \"Subtle\"},\n",
    "    {\"text\": \"The acting could have been better.\", \"aspect\": \"acting\", \"expected_sentiment\": \"negative\", \"category\": \"Subtle\"},\n",
    "    {\"text\": \"The cinematography is reasonably good.\", \"aspect\": \"cinematography\", \"expected_sentiment\": \"positive\", \"category\": \"Subtle\"},\n",
    "    {\"text\": \"The plot is somewhat lacking.\", \"aspect\": \"plot\", \"expected_sentiment\": \"negative\", \"category\": \"Subtle\"}\n",
    "]\n",
    "\n",
    "print(f\"âœ… Created {len(test_examples)} test examples\")\n",
    "categories = {}\n",
    "for example in test_examples:\n",
    "    categories[example['category']] = categories.get(example['category'], 0) + 1\n",
    "print(f\"ðŸ“Š Categories: {dict(categories)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Model predictor created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Class for performing inference with different models\n",
    "class ModelPredictor:\n",
    "    \"\"\"\n",
    "    Class for performing predictions with all models\n",
    "    \"\"\"\n",
    "    def __init__(self, models, tokenizers, device):\n",
    "        self.models = models\n",
    "        self.tokenizers = tokenizers\n",
    "        self.device = device\n",
    "        \n",
    "    def find_aspect_positions(self, text, aspect, tokenizer):\n",
    "        \"\"\"Find aspect position in tokenized text\"\"\"\n",
    "        # Tokenize text and aspect separately\n",
    "        tokens = tokenizer.tokenize(text.lower())\n",
    "        aspect_tokens = tokenizer.tokenize(aspect.lower())\n",
    "        \n",
    "        # Search for aspect token sequence\n",
    "        for i in range(len(tokens) - len(aspect_tokens) + 1):\n",
    "            if tokens[i:i+len(aspect_tokens)] == aspect_tokens:\n",
    "                return [(i+1, i+len(aspect_tokens))]  # +1 to account for [CLS] token\n",
    "        \n",
    "        # If exact match not found, search for partial match\n",
    "        aspect_lower = aspect.lower()\n",
    "        text_lower = text.lower()\n",
    "        if aspect_lower in text_lower:\n",
    "            start_char = text_lower.find(aspect_lower)\n",
    "            end_char = start_char + len(aspect_lower)\n",
    "            # Approximate position mapping\n",
    "            return [(1, 3)]  # Use approximate positions\n",
    "        \n",
    "        return [(1, 2)]  # Fallback positions\n",
    "    \n",
    "    def predict_lcf_atepc(self, text, aspect):\n",
    "        \"\"\"Prediction for LCF-ATEPC model\"\"\"\n",
    "        model = self.models['lcf_atepc']\n",
    "        tokenizer = self.tokenizers['lcf_atepc']\n",
    "        \n",
    "        # Prepare input data\n",
    "        marked_text = text\n",
    "        aspect_lower = aspect.lower().strip()\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        if aspect_lower in text_lower:\n",
    "            start_idx = text_lower.find(aspect_lower)\n",
    "            end_idx = start_idx + len(aspect_lower)\n",
    "            marked_text = f\"{text[:start_idx]}[ASPECT]{text[start_idx:end_idx]}[/ASPECT]{text[end_idx:]}\"\n",
    "        \n",
    "        # Tokenization\n",
    "        encoding = tokenizer(\n",
    "            marked_text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Find aspect positions\n",
    "        aspect_positions = self.find_aspect_positions(text, aspect, tokenizer)\n",
    "        \n",
    "        # Perform prediction\n",
    "        with torch.no_grad():\n",
    "            logits = model(\n",
    "                input_ids=encoding[\"input_ids\"],\n",
    "                attention_mask=encoding[\"attention_mask\"],\n",
    "                aspect_positions=[aspect_positions]\n",
    "            )\n",
    "            \n",
    "            if logits is not None:\n",
    "                probs = F.softmax(logits, dim=-1)\n",
    "                prediction = torch.argmax(logits, dim=-1).item()\n",
    "                confidence = probs.max().item()\n",
    "                \n",
    "                return {\n",
    "                    'prediction': prediction,\n",
    "                    'confidence': confidence,\n",
    "                    'probabilities': probs.cpu().numpy().flatten(),\n",
    "                    'sentiment': 'positive' if prediction == 1 else 'negative'\n",
    "                }\n",
    "        \n",
    "        # Fallback\n",
    "        return {\n",
    "            'prediction': 0,\n",
    "            'confidence': 0.5,\n",
    "            'probabilities': np.array([0.5, 0.5]),\n",
    "            'sentiment': 'negative'\n",
    "        }\n",
    "    \n",
    "    def predict_roberta(self, model_name, text, aspect):\n",
    "        \"\"\"Prediction for RoBERTa models\"\"\"\n",
    "        model = self.models[model_name]\n",
    "        tokenizer = self.tokenizers[model_name]\n",
    "        \n",
    "        # Prepare input text (aspect + context)\n",
    "        input_text = f\"{aspect} {tokenizer.sep_token} {text}\"\n",
    "        \n",
    "        # Tokenization\n",
    "        encoding = tokenizer(\n",
    "            input_text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Perform prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoding)\n",
    "            logits = outputs.logits\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            prediction = torch.argmax(logits, dim=-1).item()\n",
    "            confidence = probs.max().item()\n",
    "            \n",
    "            return {\n",
    "                'prediction': prediction,\n",
    "                'confidence': confidence,\n",
    "                'probabilities': probs.cpu().numpy().flatten(),\n",
    "                'sentiment': 'positive' if prediction == 1 else 'negative'\n",
    "            }\n",
    "    \n",
    "    def predict_all(self, text, aspect):\n",
    "        \"\"\"Get predictions from all models\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        # LCF-ATEPC\n",
    "        if 'lcf_atepc' in self.models:\n",
    "            results['lcf_atepc'] = self.predict_lcf_atepc(text, aspect)\n",
    "        \n",
    "        # RoBERTa models - only predict for available models\n",
    "        roberta_models = ['roberta_absa', 'roberta_absa_pseudo']\n",
    "        for model_name in roberta_models:\n",
    "            if model_name in self.models:\n",
    "                results[model_name] = self.predict_roberta(model_name, text, aspect)\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Create predictor\n",
    "predictor = ModelPredictor(loader.models, loader.tokenizers, device)\n",
    "print(\"ðŸŽ¯ Model predictor created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Running model evaluation on 30 examples...\n",
      "âœ… Evaluation completed! Processed 30 examples\n"
     ]
    }
   ],
   "source": [
    "# Run predictions for all test examples\n",
    "print(\"ðŸš€ Running model evaluation on 30 examples...\")\n",
    "\n",
    "all_results = []\n",
    "for i, example in enumerate(test_examples):\n",
    "    predictions = predictor.predict_all(example['text'], example['aspect'])\n",
    "    all_results.append({\n",
    "        'example_id': i,\n",
    "        'text': example['text'],\n",
    "        'aspect': example['aspect'],\n",
    "        'expected_sentiment': example['expected_sentiment'],\n",
    "        'category': example['category'],\n",
    "        'predictions': predictions\n",
    "    })\n",
    "\n",
    "print(f\"âœ… Evaluation completed! Processed {len(all_results)} examples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Analysis ready for 3 models on 30 examples\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics for analysis\n",
    "available_models = list(loader.models.keys())\n",
    "model_names = [name for name in ['lcf_atepc', 'roberta_absa', 'roberta_absa_pseudo'] if name in available_models]\n",
    "\n",
    "model_display_names = {\n",
    "    'lcf_atepc': 'LCF-ATEPC',\n",
    "    'roberta_absa': 'RoBERTa Base', \n",
    "    'roberta_absa_pseudo': 'RoBERTa Pseudo'\n",
    "}\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "model_accuracy = {}\n",
    "model_by_category = {}\n",
    "all_categories = list(set(r['category'] for r in all_results))\n",
    "\n",
    "for model_name in model_names:\n",
    "    correct = sum(1 for r in all_results if r['predictions'][model_name]['sentiment'] == r['expected_sentiment'])\n",
    "    model_accuracy[model_name] = correct / len(all_results)\n",
    "    \n",
    "    model_by_category[model_name] = {}\n",
    "    for category in all_categories:\n",
    "        cat_results = [r for r in all_results if r['category'] == category]\n",
    "        cat_correct = sum(1 for r in cat_results if r['predictions'][model_name]['sentiment'] == r['expected_sentiment'])\n",
    "        model_by_category[model_name][category] = cat_correct / len(cat_results) if cat_results else 0\n",
    "\n",
    "print(f\"ðŸ“Š Analysis ready for {len(model_names)} models on {len(all_results)} examples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           "#2E86AB",
           "#A23B72",
           "#F18F01"
          ]
         },
         "text": [
          "86.7%",
          "70.0%",
          "73.3%"
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "LCF-ATEPC",
          "RoBERTa Base",
          "RoBERTa Pseudo"
         ],
         "y": [
          0.8666666666666667,
          0.7,
          0.7333333333333333
         ]
        }
       ],
       "layout": {
        "height": 400,
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "ABSA Model Performance Comparison"
        },
        "yaxis": {
         "range": [
          0,
          1
         ],
         "tickformat": ".0%",
         "title": {
          "text": "Accuracy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "#2E86AB"
         },
         "name": "LCF-ATEPC",
         "type": "bar",
         "x": [
          "Subtle",
          "Contradictory",
          "Consistent"
         ],
         "y": [
          1,
          0.7333333333333333,
          1
         ]
        },
        {
         "marker": {
          "color": "#A23B72"
         },
         "name": "RoBERTa Base",
         "type": "bar",
         "x": [
          "Subtle",
          "Contradictory",
          "Consistent"
         ],
         "y": [
          0.6,
          0.5333333333333333,
          1
         ]
        },
        {
         "marker": {
          "color": "#F18F01"
         },
         "name": "RoBERTa Pseudo",
         "type": "bar",
         "x": [
          "Subtle",
          "Contradictory",
          "Consistent"
         ],
         "y": [
          0.8,
          0.5333333333333333,
          1
         ]
        }
       ],
       "layout": {
        "barmode": "group",
        "height": 400,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Model Performance by Category"
        },
        "yaxis": {
         "range": [
          0,
          1
         ],
         "tickformat": ".0%",
         "title": {
          "text": "Accuracy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interactive visualizations with Plotly\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# 1. Overall Model Performance\n",
    "fig_overall = go.Figure()\n",
    "models = [model_display_names[name] for name in model_names]\n",
    "accuracies = [model_accuracy[name] for name in model_names]\n",
    "\n",
    "fig_overall.add_trace(go.Bar(\n",
    "    x=models, y=accuracies,\n",
    "    text=[f'{acc:.1%}' for acc in accuracies],\n",
    "    textposition='auto',\n",
    "    marker_color=['#2E86AB', '#A23B72', '#F18F01'][:len(models)]\n",
    "))\n",
    "\n",
    "fig_overall.update_layout(\n",
    "    title='ABSA Model Performance Comparison',\n",
    "    yaxis_title='Accuracy',\n",
    "    yaxis=dict(range=[0, 1], tickformat='.0%'),\n",
    "    showlegend=False,\n",
    "    height=400\n",
    ")\n",
    "fig_overall.show()\n",
    "\n",
    "# 2. Performance by Category \n",
    "fig_cat = go.Figure()\n",
    "colors = ['#2E86AB', '#A23B72', '#F18F01']\n",
    "\n",
    "for i, model_name in enumerate(model_names):\n",
    "    accuracies_by_cat = [model_by_category[model_name][cat] for cat in all_categories]\n",
    "    fig_cat.add_trace(go.Bar(\n",
    "        name=model_display_names[model_name],\n",
    "        x=all_categories,\n",
    "        y=accuracies_by_cat,\n",
    "        marker_color=colors[i]\n",
    "    ))\n",
    "\n",
    "fig_cat.update_layout(\n",
    "    title='Model Performance by Category',\n",
    "    yaxis_title='Accuracy',\n",
    "    yaxis=dict(range=[0, 1], tickformat='.0%'),\n",
    "    barmode='group',\n",
    "    height=400\n",
    ")\n",
    "fig_cat.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "LCF-ATEPC",
         "nbinsx": 20,
         "opacity": 0.7,
         "type": "histogram",
         "x": {
          "bdata": "AAAAwFDm4T8AAABg1SzkPwAAAOCWF+M/AAAAAD4I7j8AAABA+DvkPwAAAKBIBeU/AAAAALu67j8AAAAgK+joPwAAAEDQIOs/AAAAIPKk5z8AAAAAqBrmPwAAAEDzAOU/AAAAoGor7j8AAACAmQvgPwAAAKDNM+M/AAAAIECs7D8AAADAMbLuPwAAAKCS7uw/AAAAIEyl7j8AAADgDr/qPwAAACCCpu4/AAAAQKtP7D8AAAAAtLbuPwAAAAApquw/AAAAYJBM6D8AAACAZRPlPwAAAMAiPO0/AAAAIOLl6D8AAAAgeKfmPwAAAKANVu4/",
          "dtype": "f8"
         },
         "xaxis": "x",
         "yaxis": "y"
        },
        {
         "name": "RoBERTa Base",
         "nbinsx": 20,
         "opacity": 0.7,
         "type": "histogram",
         "x": {
          "bdata": "AAAAAAAA8D8AAAAAAADwPwAAAMD//+8/AAAAwP//7z8AAADANf/vPwAAAIDy/+8/AAAAwP//7z8AAABA5v/vPwAAAAD+/+8/AAAAAIX/7z8AAAAAAADwPwAAAID//+8/AAAAAAAA8D8AAACA///vPwAAAAAAAPA/AAAAgP//7z8AAAAAAADwPwAAAID//+8/AAAAAAAA8D8AAAAAAADwPwAAAAAAAPA/AAAAAAAA8D8AAAAAAADwPwAAAAAAAPA/AAAAAAAA8D8AAABA4v/vPwAAAAAAAPA/AAAAAAAA8D8AAAAAAADwPwAAAMD//+8/",
          "dtype": "f8"
         },
         "xaxis": "x",
         "yaxis": "y"
        },
        {
         "name": "RoBERTa Pseudo",
         "nbinsx": 20,
         "opacity": 0.7,
         "type": "histogram",
         "x": {
          "bdata": "AAAAgHb/7z8AAADgGrjuPwAAAEA6z+8/AAAAYMp/4j8AAADAkPjvPwAAAIBLyu4/AAAAgJbf7z8AAACgkfvvPwAAAEAVOe8/AAAAgO1C6z8AAAAAEDXkPwAAAGDofe8/AAAA4P1m7T8AAAAgM77vPwAAACDCjuc/AAAAQJT/7z8AAABAxv/vPwAAAED+/u8/AAAAgL3/7z8AAADAy//vPwAAAEC6/+8/AAAAAM3/7z8AAAAAwP/vPwAAAADK/+8/AAAAQMD/7z8AAADAc7/vPwAAAMC6/+8/AAAAwLsX7z8AAACA6fzvPwAAAAANxu8/",
          "dtype": "f8"
         },
         "xaxis": "x",
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "red"
         },
         "name": "Wrong Answer Confidence",
         "opacity": 0.7,
         "type": "bar",
         "x": [
          "LCF-ATEPC",
          "RoBERTa Base",
          "RoBERTa Pseudo"
         ],
         "xaxis": "x2",
         "y": {
          "bdata": "AAAAcLXL4j+rqqqq7v/vPwAAAOTj+us/",
          "dtype": "f8"
         },
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "green"
         },
         "name": "Correct Answer Confidence",
         "opacity": 0.7,
         "type": "bar",
         "x": [
          "LCF-ATEPC",
          "RoBERTa Base",
          "RoBERTa Pseudo"
         ],
         "xaxis": "x2",
         "y": {
          "bdata": "7MRO7ANW6j+rqqpq9P/vPxdddHGuVO8/",
          "dtype": "f8"
         },
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": [
           "green",
           "orange",
           "orange"
          ]
         },
         "type": "bar",
         "x": [
          "LCF-ATEPC",
          "RoBERTa Base",
          "RoBERTa Pseudo"
         ],
         "xaxis": "x3",
         "y": [
          0.7333333333333333,
          0.5333333333333333,
          0.5333333333333333
         ],
         "yaxis": "y3"
        },
        {
         "mode": "lines+markers",
         "name": "LCF-ATEPC",
         "type": "scatter",
         "x": {
          "bdata": "mpmZmZmZqT80MzMzMzPDPwAAAAAAANA/Z2ZmZmZm1j/NzMzMzMzcP5qZmZmZmeE/zszMzMzM5D8AAAAAAADoPzQzMzMzM+s/ZmZmZmZm7j8=",
          "dtype": "f8"
         },
         "xaxis": "x4",
         "y": [
          0,
          0,
          0,
          0,
          0,
          0.3333333333333333,
          0.7142857142857143,
          1,
          1,
          1
         ],
         "yaxis": "y4"
        },
        {
         "mode": "lines+markers",
         "name": "RoBERTa Base",
         "type": "scatter",
         "x": {
          "bdata": "mpmZmZmZqT80MzMzMzPDPwAAAAAAANA/Z2ZmZmZm1j/NzMzMzMzcP5qZmZmZmeE/zszMzMzM5D8AAAAAAADoPzQzMzMzM+s/ZmZmZmZm7j8=",
          "dtype": "f8"
         },
         "xaxis": "x4",
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0.5
         ],
         "yaxis": "y4"
        },
        {
         "mode": "lines+markers",
         "name": "RoBERTa Pseudo",
         "type": "scatter",
         "x": {
          "bdata": "mpmZmZmZqT80MzMzMzPDPwAAAAAAANA/Z2ZmZmZm1j/NzMzMzMzcP5qZmZmZmeE/zszMzMzM5D8AAAAAAADoPzQzMzMzM+s/ZmZmZmZm7j8=",
          "dtype": "f8"
         },
         "xaxis": "x4",
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0.8076923076923077
         ],
         "yaxis": "y4"
        },
        {
         "line": {
          "color": "black",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "Perfect Calibration",
         "type": "scatter",
         "x": [
          0,
          1
         ],
         "xaxis": "x4",
         "y": [
          0,
          1
         ],
         "yaxis": "y4"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Confidence Distribution",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Overconfidence Analysis",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Contradictory Performance",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Calibration Curves",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 800,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Model Confidence and Overconfidence Analysis"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.55,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.625,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.625,
          1
         ]
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          0.375
         ]
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          0.375
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š OVERCONFIDENCE ANALYSIS SUMMARY:\n",
      "--------------------------------------------------\n",
      "LCF-ATEPC      : âœ… Well-calibrated (Wrong confidence: 0.587)\n",
      "RoBERTa Base   : âš ï¸ OVERCONFIDENT (Wrong confidence: 1.000)\n",
      "RoBERTa Pseudo : âš ï¸ OVERCONFIDENT (Wrong confidence: 0.874)\n"
     ]
    }
   ],
   "source": [
    "# Overconfidence Analysis for RoBERTa Models\n",
    "confidence_data = []\n",
    "for result in all_results:\n",
    "    for model_name in model_names:\n",
    "        pred = result['predictions'][model_name]\n",
    "        is_correct = pred['sentiment'] == result['expected_sentiment']\n",
    "        confidence_data.append({\n",
    "            'model': model_display_names[model_name],\n",
    "            'confidence': pred['confidence'],\n",
    "            'correct': is_correct,\n",
    "            'category': result['category']\n",
    "        })\n",
    "\n",
    "df_confidence = pd.DataFrame(confidence_data)\n",
    "\n",
    "# 3. Confidence Distribution Analysis\n",
    "fig_conf = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Confidence Distribution', 'Overconfidence Analysis', 'Contradictory Performance', 'Calibration Curves'),\n",
    "    specs=[[{'secondary_y': False}, {'secondary_y': False}],\n",
    "           [{'secondary_y': False}, {'secondary_y': False}]]\n",
    ")\n",
    "\n",
    "# Confidence distributions\n",
    "for i, model_name in enumerate(model_names):\n",
    "    model_data = df_confidence[df_confidence['model'] == model_display_names[model_name]]\n",
    "    fig_conf.add_trace(\n",
    "        go.Histogram(x=model_data['confidence'], name=model_display_names[model_name], \n",
    "                    opacity=0.7, nbinsx=20),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# Overconfidence comparison\n",
    "overconf_data = []\n",
    "for model_name in model_names:\n",
    "    model_data = df_confidence[df_confidence['model'] == model_display_names[model_name]]\n",
    "    correct_conf = model_data[model_data['correct']]['confidence'].mean()\n",
    "    incorrect_conf = model_data[~model_data['correct']]['confidence'].mean()\n",
    "    overconf_data.append({\n",
    "        'model': model_display_names[model_name],\n",
    "        'correct_confidence': correct_conf,\n",
    "        'incorrect_confidence': incorrect_conf,\n",
    "        'overconfidence': incorrect_conf - 0.5  # How much above random chance for wrong answers\n",
    "    })\n",
    "\n",
    "overconf_df = pd.DataFrame(overconf_data)\n",
    "fig_conf.add_trace(\n",
    "    go.Bar(x=overconf_df['model'], y=overconf_df['incorrect_confidence'], \n",
    "           name='Wrong Answer Confidence', marker_color='red', opacity=0.7),\n",
    "    row=1, col=2\n",
    ")\n",
    "fig_conf.add_trace(\n",
    "    go.Bar(x=overconf_df['model'], y=overconf_df['correct_confidence'], \n",
    "           name='Correct Answer Confidence', marker_color='green', opacity=0.7),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Contradictory sentiment performance\n",
    "contradictory_perf = []\n",
    "for model_name in model_names:\n",
    "    contradictory_data = df_confidence[\n",
    "        (df_confidence['model'] == model_display_names[model_name]) & \n",
    "        (df_confidence['category'] == 'Contradictory')\n",
    "    ]\n",
    "    acc = contradictory_data['correct'].mean() if len(contradictory_data) > 0 else 0\n",
    "    contradictory_perf.append(acc)\n",
    "\n",
    "fig_conf.add_trace(\n",
    "    go.Bar(x=[model_display_names[name] for name in model_names], \n",
    "           y=contradictory_perf,\n",
    "           marker_color=['green' if x > 0.6 else 'orange' if x > 0.4 else 'red' for x in contradictory_perf]),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Simple calibration visualization\n",
    "for i, model_name in enumerate(model_names):\n",
    "    model_data = df_confidence[df_confidence['model'] == model_display_names[model_name]]\n",
    "    # Bin confidences and calculate accuracy per bin\n",
    "    bins = np.linspace(0, 1, 11)\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "    bin_accuracies = []\n",
    "    \n",
    "    for j in range(len(bins)-1):\n",
    "        bin_mask = (model_data['confidence'] >= bins[j]) & (model_data['confidence'] < bins[j+1])\n",
    "        bin_data = model_data[bin_mask]\n",
    "        bin_acc = bin_data['correct'].mean() if len(bin_data) > 0 else 0\n",
    "        bin_accuracies.append(bin_acc)\n",
    "    \n",
    "    fig_conf.add_trace(\n",
    "        go.Scatter(x=bin_centers, y=bin_accuracies, \n",
    "                  name=model_display_names[model_name], mode='lines+markers'),\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "# Perfect calibration line\n",
    "fig_conf.add_trace(\n",
    "    go.Scatter(x=[0, 1], y=[0, 1], mode='lines', \n",
    "              line=dict(dash='dash', color='black'), name='Perfect Calibration'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig_conf.update_layout(height=800, title_text=\"Model Confidence and Overconfidence Analysis\")\n",
    "fig_conf.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"ðŸ“Š OVERCONFIDENCE ANALYSIS SUMMARY:\")\n",
    "print(\"-\" * 50)\n",
    "for _, row in overconf_df.iterrows():\n",
    "        status = \"âš ï¸ OVERCONFIDENT\" if row['overconfidence'] > 0.2 else \"âœ… Well-calibrated\"\n",
    "        print(f\"{row['model']:15}: {status} (Wrong confidence: {row['incorrect_confidence']:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ KEY FINDINGS:\n",
      "------------------------------\n",
      "Best Overall: LCF-ATEPC (86.7%)\n",
      "Best on Contradictory: LCF-ATEPC (73.3%)\n",
      "RoBERTa Overconfidence Issue: 0.437 (above 0.2 is concerning)\n"
     ]
    }
   ],
   "source": [
    "# Final conclusions\n",
    "best_overall = max(model_names, key=lambda x: model_accuracy[x])\n",
    "contradictory_acc = {name: model_by_category[name]['Contradictory'] for name in model_names}\n",
    "best_contradictory = max(model_names, key=lambda x: contradictory_acc[x])\n",
    "\n",
    "print(\"ðŸŽ¯ KEY FINDINGS:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Best Overall: {model_display_names[best_overall]} ({model_accuracy[best_overall]:.1%})\")\n",
    "print(f\"Best on Contradictory: {model_display_names[best_contradictory]} ({contradictory_acc[best_contradictory]:.1%})\")\n",
    "\n",
    "roberta_models = [name for name in model_names if 'roberta' in name]\n",
    "if roberta_models:\n",
    "    roberta_overconf = overconf_df[overconf_df['model'].str.contains('RoBERTa')]['overconfidence'].mean()\n",
    "    print(f\"RoBERTa Overconfidence Issue: {roberta_overconf:.3f} (above 0.2 is concerning)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š FINAL RESULTS SUMMARY:\n",
      "         Model  Overall_Accuracy  Contradictory_Accuracy  Precision  Recall  F1_Score  Overconfidence_Score Architecture\n",
      "     LCF-ATEPC             0.867                   0.733      1.000   0.733     0.846                 0.087    LCF-ATEPC\n",
      "  RoBERTa Base             0.700                   0.533      0.750   0.600     0.667                 0.500      RoBERTa\n",
      "RoBERTa Pseudo             0.733                   0.533      0.733   0.733     0.733                 0.374      RoBERTa\n",
      "\n",
      "ðŸ’¾ Results saved to model_comparison_results.csv\n",
      "âœ… Analysis completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create final metrics table\n",
    "metrics_data = []\n",
    "\n",
    "for model_name in model_names:\n",
    "    # Calculate metrics\n",
    "    y_true = [1 if r['expected_sentiment'] == 'positive' else 0 for r in all_results]\n",
    "    y_pred = [1 if r['predictions'][model_name]['sentiment'] == 'positive' else 0 for r in all_results]\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary', zero_division=0)\n",
    "    \n",
    "    # Get overconfidence data\n",
    "    model_overconf = overconf_df[overconf_df['model'] == model_display_names[model_name]]\n",
    "    overconf_score = model_overconf['overconfidence'].iloc[0] if len(model_overconf) > 0 else 0\n",
    "    \n",
    "    metrics_data.append({\n",
    "        'Model': model_display_names[model_name],\n",
    "        'Overall_Accuracy': model_accuracy[model_name],\n",
    "        'Contradictory_Accuracy': model_by_category[model_name]['Contradictory'],\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1_Score': f1,\n",
    "        'Overconfidence_Score': overconf_score,\n",
    "        'Architecture': 'LCF-ATEPC' if model_name == 'lcf_atepc' else 'RoBERTa'\n",
    "    })\n",
    "\n",
    "# Create and display table\n",
    "df_metrics = pd.DataFrame(metrics_data)\n",
    "print(\"ðŸ“Š FINAL RESULTS SUMMARY:\")\n",
    "print(df_metrics.round(3).to_string(index=False))\n",
    "\n",
    "# Save results\n",
    "df_metrics.to_csv('../models/model_comparison_results.csv', index=False)\n",
    "print(f\"\\nðŸ’¾ Results saved to model_comparison_results.csv\")\n",
    "print(\"âœ… Analysis completed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
